{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression<br>\n",
    "y = b0 + b1 * x1 + b2 * x2 + ... + bn * xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"50_Startups.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:,:4]\n",
    "Y=dataset.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "        9.1391770e+04, 3.6616842e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n",
       "        9.9814710e+04, 3.6286136e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n",
       "        1.4719887e+05, 1.2771682e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n",
       "        1.4553006e+05, 3.2387668e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n",
       "        1.4871895e+05, 3.1161329e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n",
       "        1.0867917e+05, 3.0498162e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0191308e+05,\n",
       "        1.1059411e+05, 2.2916095e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0067196e+05,\n",
       "        9.1790610e+04, 2.4974455e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n",
       "        1.2732038e+05, 2.4983944e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n",
       "        1.3549507e+05, 2.5266493e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n",
       "        1.5654742e+05, 2.5651292e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n",
       "        1.2261684e+05, 2.6177623e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n",
       "        1.2159755e+05, 2.6434606e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n",
       "        1.4507758e+05, 2.8257431e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n",
       "        1.1417579e+05, 2.9491957e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n",
       "        1.5351411e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n",
       "        1.1386730e+05, 2.9866447e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n",
       "        1.5377343e+05, 2.9973729e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.3994560e+04,\n",
       "        1.2278275e+05, 3.0331926e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n",
       "        1.0575103e+05, 3.0476873e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n",
       "        9.9281340e+04, 1.4057481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n",
       "        1.3955316e+05, 1.3796262e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n",
       "        1.4413598e+05, 1.3405007e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.2107600e+04,\n",
       "        1.2786455e+05, 3.5318381e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.6051520e+04,\n",
       "        1.8264556e+05, 1.1814820e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n",
       "        1.5303206e+05, 1.0713838e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n",
       "        1.1564128e+05, 9.1131240e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.1136380e+04,\n",
       "        1.5270192e+05, 8.8218230e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n",
       "        1.2921961e+05, 4.6085250e+04],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n",
       "        1.0305749e+05, 2.1463481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n",
       "        1.5769392e+05, 2.1079767e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n",
       "        8.5047440e+04, 2.0551764e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n",
       "        1.2705621e+05, 2.0112682e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n",
       "        5.1283140e+04, 1.9702942e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.0229590e+04,\n",
       "        6.5947930e+04, 1.8526510e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n",
       "        8.2982090e+04, 1.7499930e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n",
       "        1.1854605e+05, 1.7279567e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.7892920e+04,\n",
       "        8.4710770e+04, 1.6447071e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n",
       "        9.6189630e+04, 1.4800111e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n",
       "        1.2738230e+05, 3.5534170e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n",
       "        1.5480614e+05, 2.8334720e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n",
       "        1.2415304e+05, 1.9039300e+03],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n",
       "        1.1581621e+05, 2.9711446e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.3542692e+05, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n",
       "        5.1743150e+04, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.1698380e+05, 4.5173060e+04]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding categorical variable\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct=ColumnTransformer([(\"State\",OneHotEncoder(),[3])],remainder=\"passthrough\")\n",
    "X=ct.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 1.0000000e+00, 1.6534920e+05, 1.3689780e+05,\n",
       "        4.7178410e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.6259770e+05, 1.5137759e+05,\n",
       "        4.4389853e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.5344151e+05, 1.0114555e+05,\n",
       "        4.0793454e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 1.4437241e+05, 1.1867185e+05,\n",
       "        3.8319962e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.4210734e+05, 9.1391770e+04,\n",
       "        3.6616842e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 1.3187690e+05, 9.9814710e+04,\n",
       "        3.6286136e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.3461546e+05, 1.4719887e+05,\n",
       "        1.2771682e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.3029813e+05, 1.4553006e+05,\n",
       "        3.2387668e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 1.2054252e+05, 1.4871895e+05,\n",
       "        3.1161329e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.2333488e+05, 1.0867917e+05,\n",
       "        3.0498162e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0191308e+05, 1.1059411e+05,\n",
       "        2.2916095e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0067196e+05, 9.1790610e+04,\n",
       "        2.4974455e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 9.3863750e+04, 1.2732038e+05,\n",
       "        2.4983944e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 9.1992390e+04, 1.3549507e+05,\n",
       "        2.5266493e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.1994324e+05, 1.5654742e+05,\n",
       "        2.5651292e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 1.1452361e+05, 1.2261684e+05,\n",
       "        2.6177623e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 7.8013110e+04, 1.2159755e+05,\n",
       "        2.6434606e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 9.4657160e+04, 1.4507758e+05,\n",
       "        2.8257431e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 9.1749160e+04, 1.1417579e+05,\n",
       "        2.9491957e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 8.6419700e+04, 1.5351411e+05,\n",
       "        0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 7.6253860e+04, 1.1386730e+05,\n",
       "        2.9866447e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 7.8389470e+04, 1.5377343e+05,\n",
       "        2.9973729e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 7.3994560e+04, 1.2278275e+05,\n",
       "        3.0331926e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 6.7532530e+04, 1.0575103e+05,\n",
       "        3.0476873e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 7.7044010e+04, 9.9281340e+04,\n",
       "        1.4057481e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 6.4664710e+04, 1.3955316e+05,\n",
       "        1.3796262e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 7.5328870e+04, 1.4413598e+05,\n",
       "        1.3405007e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 7.2107600e+04, 1.2786455e+05,\n",
       "        3.5318381e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 6.6051520e+04, 1.8264556e+05,\n",
       "        1.1814820e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 6.5605480e+04, 1.5303206e+05,\n",
       "        1.0713838e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 6.1994480e+04, 1.1564128e+05,\n",
       "        9.1131240e+04],\n",
       "       [0.0000000e+00, 1.0000000e+00, 6.1136380e+04, 1.5270192e+05,\n",
       "        8.8218230e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 6.3408860e+04, 1.2921961e+05,\n",
       "        4.6085250e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 5.5493950e+04, 1.0305749e+05,\n",
       "        2.1463481e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 4.6426070e+04, 1.5769392e+05,\n",
       "        2.1079767e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 4.6014020e+04, 8.5047440e+04,\n",
       "        2.0551764e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 2.8663760e+04, 1.2705621e+05,\n",
       "        2.0112682e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 4.4069950e+04, 5.1283140e+04,\n",
       "        1.9702942e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 2.0229590e+04, 6.5947930e+04,\n",
       "        1.8526510e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 3.8558510e+04, 8.2982090e+04,\n",
       "        1.7499930e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 2.8754330e+04, 1.1854605e+05,\n",
       "        1.7279567e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 2.7892920e+04, 8.4710770e+04,\n",
       "        1.6447071e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 2.3640930e+04, 9.6189630e+04,\n",
       "        1.4800111e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 1.5505730e+04, 1.2738230e+05,\n",
       "        3.5534170e+04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 2.2177740e+04, 1.5480614e+05,\n",
       "        2.8334720e+04],\n",
       "       [0.0000000e+00, 1.0000000e+00, 1.0002300e+03, 1.2415304e+05,\n",
       "        1.9039300e+03],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.3154600e+03, 1.1581621e+05,\n",
       "        2.9711446e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3542692e+05,\n",
       "        0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 5.4205000e+02, 5.1743150e+04,\n",
       "        0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.1698380e+05,\n",
       "        4.5173060e+04]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#avoiding the dummy variable trap\n",
    "X=X[:,1:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "#we do not have to do the feature scaling manually because the library will take care of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103015.20159796, 132582.27760816, 132447.73845175,  71976.09851259,\n",
       "       178537.48221054, 116161.24230163,  67851.69209676,  98791.73374688,\n",
       "       113969.43533012, 167921.0656955 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=regressor.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "        9.1391770e+04, 3.6616842e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n",
       "        9.9814710e+04, 3.6286136e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n",
       "        1.4719887e+05, 1.2771682e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n",
       "        1.4553006e+05, 3.2387668e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n",
       "        1.4871895e+05, 3.1161329e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n",
       "        1.0867917e+05, 3.0498162e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0191308e+05,\n",
       "        1.1059411e+05, 2.2916095e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0067196e+05,\n",
       "        9.1790610e+04, 2.4974455e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n",
       "        1.2732038e+05, 2.4983944e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n",
       "        1.3549507e+05, 2.5266493e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n",
       "        1.5654742e+05, 2.5651292e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n",
       "        1.2261684e+05, 2.6177623e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n",
       "        1.2159755e+05, 2.6434606e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n",
       "        1.4507758e+05, 2.8257431e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n",
       "        1.1417579e+05, 2.9491957e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n",
       "        1.5351411e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n",
       "        1.1386730e+05, 2.9866447e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n",
       "        1.5377343e+05, 2.9973729e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.3994560e+04,\n",
       "        1.2278275e+05, 3.0331926e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n",
       "        1.0575103e+05, 3.0476873e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n",
       "        9.9281340e+04, 1.4057481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n",
       "        1.3955316e+05, 1.3796262e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n",
       "        1.4413598e+05, 1.3405007e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.2107600e+04,\n",
       "        1.2786455e+05, 3.5318381e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.6051520e+04,\n",
       "        1.8264556e+05, 1.1814820e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n",
       "        1.5303206e+05, 1.0713838e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n",
       "        1.1564128e+05, 9.1131240e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.1136380e+04,\n",
       "        1.5270192e+05, 8.8218230e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n",
       "        1.2921961e+05, 4.6085250e+04],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n",
       "        1.0305749e+05, 2.1463481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n",
       "        1.5769392e+05, 2.1079767e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n",
       "        8.5047440e+04, 2.0551764e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n",
       "        1.2705621e+05, 2.0112682e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n",
       "        5.1283140e+04, 1.9702942e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.0229590e+04,\n",
       "        6.5947930e+04, 1.8526510e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n",
       "        8.2982090e+04, 1.7499930e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n",
       "        1.1854605e+05, 1.7279567e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.7892920e+04,\n",
       "        8.4710770e+04, 1.6447071e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n",
       "        9.6189630e+04, 1.4800111e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n",
       "        1.2738230e+05, 3.5534170e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n",
       "        1.5480614e+05, 2.8334720e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n",
       "        1.2415304e+05, 1.9039300e+03],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n",
       "        1.1581621e+05, 2.9711446e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.3542692e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n",
       "        5.1743150e+04, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.1698380e+05, 4.5173060e+04]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the optimal model using Backward elimination\n",
    "import statsmodels.api as sm \n",
    "#we need to add the b0 term in the data because the statsmodels does not itself take into the account b0 term of the linear regression \n",
    "#and we can do that by adding the column containing 1s in the data and hence our eq becomes y = b0 * 1 + bn + xn for mltiple linear regression\n",
    "#b0 * 1 is nothing but b0 * x ** 0 which means x ** 0 = 1\n",
    "X=np.append(arr=np.ones((50,1)).astype(int),values=X,axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the step 2 of the backward elimination\n",
    "X_opt=X[:,[0,1,2,3,4,5]]\n",
    "regressor_OLS=sm.OLS(endog=Y,exog=X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:11:30</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Profit      & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.945   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     169.9   \\\\\n",
       "\\textbf{Date:}             & Sat, 27 Apr 2024 & \\textbf{  Prob (F-statistic):} &  1.34e-27   \\\\\n",
       "\\textbf{Time:}             &     00:11:30     & \\textbf{  Log-Likelihood:    } &   -525.38   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Residuals:}     &          44      & \\textbf{  BIC:               } &     1074.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.013e+04  &     6884.820     &     7.281  &         0.000        &     3.62e+04    &      6.4e+04     \\\\\n",
       "\\textbf{x1}    &     198.7888  &     3371.007     &     0.059  &         0.953        &    -6595.030    &     6992.607     \\\\\n",
       "\\textbf{x2}    &     -41.8870  &     3256.039     &    -0.013  &         0.990        &    -6604.003    &     6520.229     \\\\\n",
       "\\textbf{x3}    &       0.8060  &        0.046     &    17.369  &         0.000        &        0.712    &        0.900     \\\\\n",
       "\\textbf{x4}    &      -0.0270  &        0.052     &    -0.517  &         0.608        &       -0.132    &        0.078     \\\\\n",
       "\\textbf{x5}    &       0.0270  &        0.017     &     1.574  &         0.123        &       -0.008    &        0.062     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.782 & \\textbf{  Durbin-Watson:     } &    1.283  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.266  \\\\\n",
       "\\textbf{Skew:}          & -0.948 & \\textbf{  Prob(JB):          } & 2.41e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.572 & \\textbf{  Cond. No.          } & 1.45e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.45e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Sat, 27 Apr 2024   Prob (F-statistic):           1.34e-27\n",
       "Time:                        00:11:30   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the step 3\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:16:30</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Profit      & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.946   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     217.2   \\\\\n",
       "\\textbf{Date:}             & Sat, 27 Apr 2024 & \\textbf{  Prob (F-statistic):} &  8.49e-29   \\\\\n",
       "\\textbf{Time:}             &     00:16:30     & \\textbf{  Log-Likelihood:    } &   -525.38   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1061.   \\\\\n",
       "\\textbf{Df Residuals:}     &          45      & \\textbf{  BIC:               } &     1070.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.011e+04  &     6647.870     &     7.537  &         0.000        &     3.67e+04    &     6.35e+04     \\\\\n",
       "\\textbf{x1}    &     220.1585  &     2900.536     &     0.076  &         0.940        &    -5621.821    &     6062.138     \\\\\n",
       "\\textbf{x2}    &       0.8060  &        0.046     &    17.606  &         0.000        &        0.714    &        0.898     \\\\\n",
       "\\textbf{x3}    &      -0.0270  &        0.052     &    -0.523  &         0.604        &       -0.131    &        0.077     \\\\\n",
       "\\textbf{x4}    &       0.0270  &        0.017     &     1.592  &         0.118        &       -0.007    &        0.061     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.758 & \\textbf{  Durbin-Watson:     } &    1.282  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.172  \\\\\n",
       "\\textbf{Skew:}          & -0.948 & \\textbf{  Prob(JB):          } & 2.53e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.563 & \\textbf{  Cond. No.          } & 1.40e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Sat, 27 Apr 2024   Prob (F-statistic):           8.49e-29\n",
       "Time:                        00:16:30   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the step 2 of the backward elimination but now we know the x2 has the p>sl therefore remove it and fit the model without it\n",
    "X_opt=X[:,[0,1,3,4,5]] # removed x2\n",
    "regressor_OLS=sm.OLS(endog=Y,exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:18:21</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Profit      & \\textbf{  R-squared:         } &     0.951   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     296.0   \\\\\n",
       "\\textbf{Date:}             & Sat, 27 Apr 2024 & \\textbf{  Prob (F-statistic):} &  4.53e-30   \\\\\n",
       "\\textbf{Time:}             &     00:18:21     & \\textbf{  Log-Likelihood:    } &   -525.39   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1059.   \\\\\n",
       "\\textbf{Df Residuals:}     &          46      & \\textbf{  BIC:               } &     1066.   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    5.012e+04  &     6572.353     &     7.626  &         0.000        &     3.69e+04    &     6.34e+04     \\\\\n",
       "\\textbf{x1}    &       0.8057  &        0.045     &    17.846  &         0.000        &        0.715    &        0.897     \\\\\n",
       "\\textbf{x2}    &      -0.0268  &        0.051     &    -0.526  &         0.602        &       -0.130    &        0.076     \\\\\n",
       "\\textbf{x3}    &       0.0272  &        0.016     &     1.655  &         0.105        &       -0.006    &        0.060     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.838 & \\textbf{  Durbin-Watson:     } &    1.282  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.442  \\\\\n",
       "\\textbf{Skew:}          & -0.949 & \\textbf{  Prob(JB):          } & 2.21e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.586 & \\textbf{  Cond. No.          } & 1.40e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Sat, 27 Apr 2024   Prob (F-statistic):           4.53e-30\n",
       "Time:                        00:18:21   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt=X[:,[0,3,4,5]] # removed x2\n",
    "regressor_OLS=sm.OLS(endog=Y,exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:19:21</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Profit      & \\textbf{  R-squared:         } &     0.950   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.948   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     450.8   \\\\\n",
       "\\textbf{Date:}             & Sat, 27 Apr 2024 & \\textbf{  Prob (F-statistic):} &  2.16e-31   \\\\\n",
       "\\textbf{Time:}             &     00:19:21     & \\textbf{  Log-Likelihood:    } &   -525.54   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1057.   \\\\\n",
       "\\textbf{Df Residuals:}     &          47      & \\textbf{  BIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.698e+04  &     2689.933     &    17.464  &         0.000        &     4.16e+04    &     5.24e+04     \\\\\n",
       "\\textbf{x1}    &       0.7966  &        0.041     &    19.266  &         0.000        &        0.713    &        0.880     \\\\\n",
       "\\textbf{x2}    &       0.0299  &        0.016     &     1.927  &         0.060        &       -0.001    &        0.061     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.677 & \\textbf{  Durbin-Watson:     } &    1.257  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   21.161  \\\\\n",
       "\\textbf{Skew:}          & -0.939 & \\textbf{  Prob(JB):          } & 2.54e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.575 & \\textbf{  Cond. No.          } & 5.32e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 5.32e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Sat, 27 Apr 2024   Prob (F-statistic):           2.16e-31\n",
       "Time:                        00:19:21   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt=X[:,[0,3,5]] # removed x2\n",
    "regressor_OLS=sm.OLS(endog=Y,exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:20:52</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Profit      & \\textbf{  R-squared:         } &     0.947   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.945   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     849.8   \\\\\n",
       "\\textbf{Date:}             & Sat, 27 Apr 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-32   \\\\\n",
       "\\textbf{Time:}             &     00:20:52     & \\textbf{  Log-Likelihood:    } &   -527.44   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1059.   \\\\\n",
       "\\textbf{Df Residuals:}     &          48      & \\textbf{  BIC:               } &     1063.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    4.903e+04  &     2537.897     &    19.320  &         0.000        &     4.39e+04    &     5.41e+04     \\\\\n",
       "\\textbf{x1}    &       0.8543  &        0.029     &    29.151  &         0.000        &        0.795    &        0.913     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 13.727 & \\textbf{  Durbin-Watson:     } &    1.116  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   18.536  \\\\\n",
       "\\textbf{Skew:}          & -0.911 & \\textbf{  Prob(JB):          } & 9.44e-05  \\\\\n",
       "\\textbf{Kurtosis:}      &  5.361 & \\textbf{  Cond. No.          } & 1.65e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.65e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Sat, 27 Apr 2024   Prob (F-statistic):           3.50e-32\n",
       "Time:                        00:20:52   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt=X[:,[0,3]] # removed x2\n",
    "regressor_OLS=sm.OLS(endog=Y,exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#therefore using the backward elimination it can be infered that the R&D spend had the strongest impact in predicting the profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush.LAPTOP-77UT5OAS\\AppData\\Local\\Temp\\ipykernel_19480\\54118890.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
      "C:\\Users\\Ayush.LAPTOP-77UT5OAS\\AppData\\Local\\Temp\\ipykernel_19480\\54118890.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
      "C:\\Users\\Ayush.LAPTOP-77UT5OAS\\AppData\\Local\\Temp\\ipykernel_19480\\54118890.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
      "C:\\Users\\Ayush.LAPTOP-77UT5OAS\\AppData\\Local\\Temp\\ipykernel_19480\\54118890.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.6534920e+05],\n",
       "       [1.0000000e+00, 1.6259770e+05],\n",
       "       [1.0000000e+00, 1.5344151e+05],\n",
       "       [1.0000000e+00, 1.4437241e+05],\n",
       "       [1.0000000e+00, 1.4210734e+05],\n",
       "       [1.0000000e+00, 1.3187690e+05],\n",
       "       [1.0000000e+00, 1.3461546e+05],\n",
       "       [1.0000000e+00, 1.3029813e+05],\n",
       "       [1.0000000e+00, 1.2054252e+05],\n",
       "       [1.0000000e+00, 1.2333488e+05],\n",
       "       [1.0000000e+00, 1.0191308e+05],\n",
       "       [1.0000000e+00, 1.0067196e+05],\n",
       "       [1.0000000e+00, 9.3863750e+04],\n",
       "       [1.0000000e+00, 9.1992390e+04],\n",
       "       [1.0000000e+00, 1.1994324e+05],\n",
       "       [1.0000000e+00, 1.1452361e+05],\n",
       "       [1.0000000e+00, 7.8013110e+04],\n",
       "       [1.0000000e+00, 9.4657160e+04],\n",
       "       [1.0000000e+00, 9.1749160e+04],\n",
       "       [1.0000000e+00, 8.6419700e+04],\n",
       "       [1.0000000e+00, 7.6253860e+04],\n",
       "       [1.0000000e+00, 7.8389470e+04],\n",
       "       [1.0000000e+00, 7.3994560e+04],\n",
       "       [1.0000000e+00, 6.7532530e+04],\n",
       "       [1.0000000e+00, 7.7044010e+04],\n",
       "       [1.0000000e+00, 6.4664710e+04],\n",
       "       [1.0000000e+00, 7.5328870e+04],\n",
       "       [1.0000000e+00, 7.2107600e+04],\n",
       "       [1.0000000e+00, 6.6051520e+04],\n",
       "       [1.0000000e+00, 6.5605480e+04],\n",
       "       [1.0000000e+00, 6.1994480e+04],\n",
       "       [1.0000000e+00, 6.1136380e+04],\n",
       "       [1.0000000e+00, 6.3408860e+04],\n",
       "       [1.0000000e+00, 5.5493950e+04],\n",
       "       [1.0000000e+00, 4.6426070e+04],\n",
       "       [1.0000000e+00, 4.6014020e+04],\n",
       "       [1.0000000e+00, 2.8663760e+04],\n",
       "       [1.0000000e+00, 4.4069950e+04],\n",
       "       [1.0000000e+00, 2.0229590e+04],\n",
       "       [1.0000000e+00, 3.8558510e+04],\n",
       "       [1.0000000e+00, 2.8754330e+04],\n",
       "       [1.0000000e+00, 2.7892920e+04],\n",
       "       [1.0000000e+00, 2.3640930e+04],\n",
       "       [1.0000000e+00, 1.5505730e+04],\n",
       "       [1.0000000e+00, 2.2177740e+04],\n",
       "       [1.0000000e+00, 1.0002300e+03],\n",
       "       [1.0000000e+00, 1.3154600e+03],\n",
       "       [1.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 5.4205000e+02],\n",
       "       [1.0000000e+00, 0.0000000e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#following code can be used to implement the backward elimination automatically rather than doing all the iterations manually\n",
    "import statsmodels.api as sm\n",
    "def backwardElimination(x, sl):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(Y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    " \n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)\n",
    "X_Modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Profit   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     450.8\n",
      "Date:                Sat, 27 Apr 2024   Prob (F-statistic):           2.16e-31\n",
      "Time:                        00:38:16   Log-Likelihood:                -525.54\n",
      "No. Observations:                  50   AIC:                             1057.\n",
      "Df Residuals:                      47   BIC:                             1063.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
      "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
      "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
      "==============================================================================\n",
      "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
      "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
      "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush.LAPTOP-77UT5OAS\\AppData\\Local\\Temp\\ipykernel_19480\\2401989041.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
      "C:\\Users\\Ayush.LAPTOP-77UT5OAS\\AppData\\Local\\Temp\\ipykernel_19480\\2401989041.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
      "C:\\Users\\Ayush.LAPTOP-77UT5OAS\\AppData\\Local\\Temp\\ipykernel_19480\\2401989041.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
      "C:\\Users\\Ayush.LAPTOP-77UT5OAS\\AppData\\Local\\Temp\\ipykernel_19480\\2401989041.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.6534920e+05, 4.7178400e+05],\n",
       "       [1.0000000e+00, 1.6259770e+05, 4.4389800e+05],\n",
       "       [1.0000000e+00, 1.5344151e+05, 4.0793400e+05],\n",
       "       [1.0000000e+00, 1.4437241e+05, 3.8319900e+05],\n",
       "       [1.0000000e+00, 1.4210734e+05, 3.6616800e+05],\n",
       "       [1.0000000e+00, 1.3187690e+05, 3.6286100e+05],\n",
       "       [1.0000000e+00, 1.3461546e+05, 1.2771600e+05],\n",
       "       [1.0000000e+00, 1.3029813e+05, 3.2387600e+05],\n",
       "       [1.0000000e+00, 1.2054252e+05, 3.1161300e+05],\n",
       "       [1.0000000e+00, 1.2333488e+05, 3.0498100e+05],\n",
       "       [1.0000000e+00, 1.0191308e+05, 2.2916000e+05],\n",
       "       [1.0000000e+00, 1.0067196e+05, 2.4974400e+05],\n",
       "       [1.0000000e+00, 9.3863750e+04, 2.4983900e+05],\n",
       "       [1.0000000e+00, 9.1992390e+04, 2.5266400e+05],\n",
       "       [1.0000000e+00, 1.1994324e+05, 2.5651200e+05],\n",
       "       [1.0000000e+00, 1.1452361e+05, 2.6177600e+05],\n",
       "       [1.0000000e+00, 7.8013110e+04, 2.6434600e+05],\n",
       "       [1.0000000e+00, 9.4657160e+04, 2.8257400e+05],\n",
       "       [1.0000000e+00, 9.1749160e+04, 2.9491900e+05],\n",
       "       [1.0000000e+00, 8.6419700e+04, 0.0000000e+00],\n",
       "       [1.0000000e+00, 7.6253860e+04, 2.9866400e+05],\n",
       "       [1.0000000e+00, 7.8389470e+04, 2.9973700e+05],\n",
       "       [1.0000000e+00, 7.3994560e+04, 3.0331900e+05],\n",
       "       [1.0000000e+00, 6.7532530e+04, 3.0476800e+05],\n",
       "       [1.0000000e+00, 7.7044010e+04, 1.4057400e+05],\n",
       "       [1.0000000e+00, 6.4664710e+04, 1.3796200e+05],\n",
       "       [1.0000000e+00, 7.5328870e+04, 1.3405000e+05],\n",
       "       [1.0000000e+00, 7.2107600e+04, 3.5318300e+05],\n",
       "       [1.0000000e+00, 6.6051520e+04, 1.1814800e+05],\n",
       "       [1.0000000e+00, 6.5605480e+04, 1.0713800e+05],\n",
       "       [1.0000000e+00, 6.1994480e+04, 9.1131000e+04],\n",
       "       [1.0000000e+00, 6.1136380e+04, 8.8218000e+04],\n",
       "       [1.0000000e+00, 6.3408860e+04, 4.6085000e+04],\n",
       "       [1.0000000e+00, 5.5493950e+04, 2.1463400e+05],\n",
       "       [1.0000000e+00, 4.6426070e+04, 2.1079700e+05],\n",
       "       [1.0000000e+00, 4.6014020e+04, 2.0551700e+05],\n",
       "       [1.0000000e+00, 2.8663760e+04, 2.0112600e+05],\n",
       "       [1.0000000e+00, 4.4069950e+04, 1.9702900e+05],\n",
       "       [1.0000000e+00, 2.0229590e+04, 1.8526500e+05],\n",
       "       [1.0000000e+00, 3.8558510e+04, 1.7499900e+05],\n",
       "       [1.0000000e+00, 2.8754330e+04, 1.7279500e+05],\n",
       "       [1.0000000e+00, 2.7892920e+04, 1.6447000e+05],\n",
       "       [1.0000000e+00, 2.3640930e+04, 1.4800100e+05],\n",
       "       [1.0000000e+00, 1.5505730e+04, 3.5534000e+04],\n",
       "       [1.0000000e+00, 2.2177740e+04, 2.8334000e+04],\n",
       "       [1.0000000e+00, 1.0002300e+03, 1.9030000e+03],\n",
       "       [1.0000000e+00, 1.3154600e+03, 2.9711400e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [1.0000000e+00, 5.4205000e+02, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 4.5173000e+04]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Backward Elimination with p-values and Adjusted R Squared:\n",
    "\n",
    "import statsmodels.api as sm\n",
    "def backwardElimination(x, SL):\n",
    "    numVars = len(x[0])\n",
    "    temp = np.zeros((50,6)).astype(int)\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(Y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues)\n",
    "        adjR_before = regressor_OLS.rsquared_adj.astype(float)\n",
    "        if maxVar > SL:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    temp[:,j] = x[:, j]\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    tmp_regressor = sm.OLS(Y, x).fit()\n",
    "                    adjR_after = tmp_regressor.rsquared_adj.astype(float)\n",
    "                    if (adjR_before >= adjR_after):\n",
    "                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n",
    "                        x_rollback = np.delete(x_rollback, j, 1)\n",
    "                        print (regressor_OLS.summary())\n",
    "                        return x_rollback\n",
    "                    else:\n",
    "                        continue\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    " \n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_Modeled = backwardElimination(X_opt, SL)\n",
    "X_Modeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the backward elimination with p vlaues and adjusted r squared it is clear that the marketing spend column also had the significant impact on the predicitions and should be included in building the model<br>\n",
    "It also makes it clear that using backward elimination with only consideration of the p values does not always produce best results and other metrics like adjusted r squared should also be taken into the account"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
